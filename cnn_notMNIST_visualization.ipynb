{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized CNN for notMNIST digit classification with tensorboard visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will build a network which is deeper than the  one in  and LeNet5.\n",
    "\n",
    "The achitecture is:\n",
    "Input(N,28, 28,1)->{conv(5,5,32, s=1)+ReLu+MaxPool(2,2)}->{conv(5,5,64, s=2)+ReLu+MaxPool(2,2)}->Flatten->FC(1000)->FC(10)->Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Test set (10000, 28, 28) (10000,)\n",
      "Training set (200000, 28, 28, 1) (200000, 10)\n",
      "Test set (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "#from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  #valid_dataset = save['valid_dataset']\n",
    "  #valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  #print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)\n",
    "\n",
    "#%%\n",
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "#valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "#print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use namepace and tensorboard to visualize the network in a better structure. \n",
    "we will get something like this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNNtensor](./CNNtensor.png))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "batch_size = 16\n",
    "filter_size = 5\n",
    "in_image_channnels = 1 #grayscale image\n",
    "depth1 = 32 #no of channels in conv1 layer\n",
    "depth2 = 64 #no of channels in conv2 layer\n",
    "num_hidden = 100\n",
    "learning_rate = 0.05\n",
    "# define location to store the tensorboard visualization files\n",
    "STORE_PATH = './../../graph/' \n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \"\"\"\n",
    "    tensorflow conv2d requires 4D input and filter tensor;\n",
    "    tf.nn.conv2d(\n",
    "        input,\n",
    "        filter,\n",
    "        strides,\n",
    "        padding,...)\n",
    "    input tensor of shape = [batch, in_height, in_width, in_channels]\n",
    "    filter / kernel tensor of shape = [filter_height, filter_width, in_channels, out_channels]\n",
    "    \"\"\"\n",
    "    \n",
    "    #define a function that creates convolutional layer\n",
    "    def create_conv_layer(in_data, num_in_channels, num_out_channels, filter_shape,conv_stride, name, use_subsample= 1):\n",
    "        ''' in_data = input Data (need 4D shape defined above)\n",
    "            in_channels = no of channels in input image, 1(grayscale), 3(RGB)\n",
    "            out_channels = depth of conv layers\n",
    "            filter_shape = filter shape used for convolution, for e.g. [3,3], or [5,5]\n",
    "            name = any valid string'''\n",
    "        #define 4D shape for filter/kernel tensor that will be used for creating weights\n",
    "        conv_filter_shape = [filter_shape[0], filter_shape[1], num_in_channels, num_out_channels]\n",
    "        \n",
    "        weights = tf.Variable(tf.truncated_normal(conv_filter_shape, stddev = 0.1), name = name+ '_W')\n",
    "        bias = tf.Variable(tf.zeros(num_out_channels), name = name+\"_b\")\n",
    "        \n",
    "        strides = [1, conv_stride[0], conv_stride[1], 1]\n",
    "        #define the conv2d layer\n",
    "        outlayer = tf.nn.conv2d(in_data, weights, strides = strides, padding = 'SAME')\n",
    "        #add bias\n",
    "        outlayer = outlayer + bias\n",
    "        #apply ReLu activation\n",
    "        outlayer = tf.nn.relu(outlayer)\n",
    "        \n",
    "        if(use_subsample== 1):\n",
    "            ## now perform max pooling\n",
    "            # define the 4D dimension of pooling filter =[1, pool_filter_x, pool_filter_y, 1]\n",
    "            ksize = [1, 2, 2, 1]\n",
    "            # now define stride for pool-layer =[1, x-strides, y-strides, 1]\n",
    "            pool_stride  = [1, 2, 2, 1]\n",
    "            outlayer = tf.nn.max_pool( outlayer, ksize, strides = pool_stride, padding ='SAME')\n",
    "        return outlayer\n",
    "    \n",
    "    # the dataset train_dataset, train_labels is already formatted\n",
    "    # Input data placeholders\n",
    "    # using shape = [None, ] allows us to use it as a general label placeholder\n",
    "    # shape=(batch_size, image_size, image_size, in_image_channnels)\n",
    "    with tf.name_scope('inputs'):\n",
    "        tf_train_dataset = tf.placeholder(tf.float32, shape=(None, image_size, image_size, in_image_channnels))\n",
    "        #tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "        tf_train_labels = tf.placeholder(tf.float32, shape=(None, num_labels))\n",
    "        #tf_valid_dataset = tf.constant(valid_dataset)\n",
    "        #tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # MODEL definition\n",
    "    # now define the two conv layer\n",
    "    with tf.name_scope('layer1'):\n",
    "        layer1 = create_conv_layer(tf_train_dataset, in_image_channnels, depth1,\\\n",
    "                               filter_shape =[5,5],conv_stride =[1,1], name ='layer1')\n",
    "    with tf.name_scope('layer2'):\n",
    "        layer2 = create_conv_layer(layer1,depth1, depth2, [5,5], [1,1], name ='layer2' )\n",
    "    \n",
    "    # now we need to flatten and add two FC layers\n",
    "    # after two layers with max-pool of stride =2, we go from 28 x 28, to 14 x 14 to 7 x 7 x,y co-ordinates, \n",
    "    # but with 16 output channels.  To create the fully connected,\n",
    "    # \"dense\" layer, the new shape needs to be [-1, 7 x 7 x 16]\n",
    "    #flattened = tf.reshape(layer2, [-1, 7 * 7 * 16])\n",
    "    flattened = tf.reshape(layer2, [-1, 7 * 7 * depth2])\n",
    "    \n",
    "    #setup weights and bias for dense layer1\n",
    "    with tf.name_scope('dense_layer1'):\n",
    "        w1 = tf.Variable(tf.truncated_normal([7*7* depth2, num_hidden], stddev = 0.1), name ='w_dense1')\n",
    "        b1 = tf.Variable(tf.zeros([num_hidden]), name ='b_dense1')\n",
    "        # fully connected layer1\n",
    "        dense_layer1 = tf.nn.relu(tf.matmul(flattened, w1) + b1)\n",
    "    \n",
    "    # weights and bias for dense layer2\n",
    "    with tf.name_scope('dense_layer2'):\n",
    "        w2 = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev = 0.1), name ='w_dense2')\n",
    "        b2 = tf.Variable(tf.zeros([num_labels]), name = 'b_dense2')\n",
    "        # define the output logits = dense_layer2\n",
    "        logits = tf.matmul(dense_layer1, w2) + b2\n",
    "        tf.summary.histogram(\"logits\", logits)\n",
    "    \n",
    "    # get the logits from the model\n",
    "    #logits = dense_layer2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels, logits=logits))\n",
    "        \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    # define an accuracy assessment operation\n",
    "    with tf.name_scope('acuuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(tf_train_labels, 1))\n",
    "        accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # add a summary to store the accuracy\n",
    "    tf.summary.scalar('acc_summary', accuracy_op)\n",
    "    tf.summary.scalar('loss_summary', loss)\n",
    "    \n",
    "    # define image summaries\n",
    "    with tf.variable_scope('getimages'):\n",
    "        correct_inputs = tf.boolean_mask(tf_train_dataset, correct_prediction)\n",
    "        image_summ_true = tf.summary.image('good_images', correct_inputs, max_outputs=5)\n",
    "        incorrect_inputs = tf.boolean_mask(tf_train_dataset, tf.logical_not(correct_prediction))\n",
    "        image_summ_false = tf.summary.image('bad_images', incorrect_inputs, max_outputs=5)\n",
    "    merged = tf.summary.merge_all()\n",
    "    #end of model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      " Total training dataset length:  200000\n",
      " total no of batches:  12500\n",
      "At Step = 42000, Minibatch train_accuracy = 0.937500 \n",
      "At Step = 44000, Minibatch train_accuracy = 0.937500 \n",
      "At Step = 46000, Minibatch train_accuracy = 1.000000 \n",
      "At Step = 48000, Minibatch train_accuracy = 1.000000 \n",
      "At Step = 50000, Minibatch train_accuracy = 1.000000 \n",
      "At Step = 52000, Minibatch train_accuracy = 0.937500 \n",
      "Epoch: 1 cost = 0.560  test accuracy: 95.13%\n",
      "At Step = 54000, Minibatch train_accuracy = 1.000000 \n",
      "At Step = 56000, Minibatch train_accuracy = 0.937500 \n",
      "At Step = 58000, Minibatch train_accuracy = 1.000000 \n",
      "At Step = 60000, Minibatch train_accuracy = 1.000000 \n",
      "At Step = 62000, Minibatch train_accuracy = 1.000000 \n",
      "At Step = 64000, Minibatch train_accuracy = 0.875000 \n",
      "Epoch: 2 cost = 0.635  test accuracy: 95.96%\n",
      "At Step = 66000, Minibatch train_accuracy = 0.937500 \n",
      "At Step = 68000, Minibatch train_accuracy = 1.000000 \n",
      "At Step = 70000, Minibatch train_accuracy = 0.875000 \n",
      "At Step = 72000, Minibatch train_accuracy = 1.000000 \n",
      "At Step = 74000, Minibatch train_accuracy = 1.000000 \n",
      "At Step = 76000, Minibatch train_accuracy = 1.000000 \n",
      "At Step = 78000, Minibatch train_accuracy = 1.000000 \n",
      "Epoch: 3 cost = 0.463  test accuracy: 96.18%\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# now training part\n",
    "epochs = 3\n",
    "summary_step =0\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    writer = tf.summary.FileWriter(STORE_PATH, session.graph)\n",
    "    total_batches = int(train_labels.shape[0]/batch_size)\n",
    "    #total_batches = 1001 # = num_Steps\n",
    "    print(\" Total training dataset length: \", len(train_labels))\n",
    "    print(\" total no of batches: \", total_batches)\n",
    "    for epoch in range(epochs):\n",
    "      for i in range(total_batches):\n",
    "          offset = (i * batch_size)\n",
    "          batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "          batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "          feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "          _, l, summary = session.run([optimizer, loss,merged], feed_dict=feed_dict)\n",
    "          global_step +=1\n",
    "          if (global_step% 2000 == 0):\n",
    "                writer.add_summary(summary, global_step//1999)\n",
    "                print(\"At Step = %d, Minibatch train_accuracy = %f \" \\\n",
    "                      %(global_step,session.run(accuracy_op, feed_dict = feed_dict)))\n",
    "          del batch_data, batch_labels, feed_dict\n",
    "      test_len = int(len(test_labels)/2) # only taking half length\n",
    "      test_acc1 = session.run(accuracy_op, \\\n",
    "                             feed_dict ={tf_train_dataset:test_dataset[0:test_len, :, :, :],tf_train_labels: test_labels[0:test_len, :]})\n",
    "      test_acc2 = session.run(accuracy_op, \\\n",
    "                             feed_dict ={tf_train_dataset:test_dataset[test_len:, :, :, :],tf_train_labels: test_labels[test_len:, :]})\n",
    "      # find the avg test acuuracy from the accuracy of 1st half and 2nd half\n",
    "      test_acc = (test_acc1 + test_acc2) /2.0\n",
    "      print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(l), \" test accuracy: {:.2f}%\".format(test_acc*100))\n",
    "print(\"\\nTraining complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following in command prompt; we need to point to the STORE_PATH directory \n",
    "\n",
    "$ tensorboard --logdir=path_to_store_dir\n",
    "\n",
    "Ctrl+click on the link and you would see the following:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default tab is **\"scalars\"**. Here you would see the \"loss\" and \"accurary\" over sampled training iterations.\n",
    "![tensorboard](./tensorboard.png))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on the **Graph** tab to see the graphical representation of the model;\n",
    "\n",
    "Click  on the **images** tab to check sample of good and bad cases.\n",
    "\n",
    "Feel free to zoom in and check the variables dimension and individual blocks.\n",
    "\n",
    "![tensorboard-graph.png](./tensorboard-graph.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
